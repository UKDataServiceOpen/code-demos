{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "![UKDS Logo](./images/UKDS_Logos_Col_Grey_300dpi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Collecting Data II: APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Welcome to the <a href=\"https://ukdataservice.ac.uk/\" target=_blank>UK Data Service</a> training series on *New Forms of Data for Social Science Research*. This series guides you through some of the most common and valuable new sources of data available for social science research: data collected from websites, social media platorms, text data, conducting simulations (agent based modelling), to name a few. To help you get to grips with these new forms of data, we provide webinars, interactive notebooks containing live programming code, reading lists and more.\n",
    "\n",
    "* To access training materials for the entire series: <a href=\"https://github.com/UKDataServiceOpen/new-forms-of-data\" target=_blank>[Training Materials]</a>\n",
    "\n",
    "* To keep up to date with upcoming and past training events: <a href=\"https://ukdataservice.ac.uk/news-and-events/events\" target=_blank>[Events]</a>\n",
    "\n",
    "* To get in contact with feedback, ideas or to seek assistance: <a href=\"https://ukdataservice.ac.uk/help.aspx\" target=_blank>[Help]</a>\n",
    "\n",
    "<a href=\"https://www.research.manchester.ac.uk/portal/julia.kasmire.html\" target=_blank>Dr Julia Kasmire</a> and <a href=\"https://www.research.manchester.ac.uk/portal/diarmuid.mcdonnell.html\" target=_blank>Dr Diarmuid McDonnell</a> <br />\n",
    "UK Data Service  <br />\n",
    "University of Manchester <br />\n",
    "May 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Computational methods for collecting, cleaning and analysing data are an increasingly important component of a social scientistâ€™s toolkit. Central to engaging in these methods is the ability to write readable and effective code using a programming language.\n",
    "\n",
    "In this training series we demonstrate core programming concepts and methods through the use of social science examples. In particular we focus on four areas of programming/computational social science:\n",
    "1. Introduction to Python.\n",
    "2. Collecting data I: web-scraping. \n",
    "3. Collecting data II: APIs. [Focus of this notebook]\n",
    "4. Setting up your computational environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aims\n",
    "\n",
    "This lesson - **Collecting data II: APIs** - has two aims:\n",
    "1. Demonstrate how to use Python to download data from the web through an Application Programming Interface (API).\n",
    "2. Cultivate your computational thinking skills through coding examples. In particular, how to define and solve a data collection problem using a computational method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lesson details\n",
    "\n",
    "* **Level**: Introductory\n",
    "* **Time**: 30-60 minutes\n",
    "* **Pre-requisites**: None, though you may find it useful to work through our <a href=\"https://github.com/UKDataServiceOpen/code-demos/blob/master/code/ukds-intro-to-python-2020-05-06.ipynb\" target=_blank>*Introduction to Python for social scientists*</a> and <a href=\"https://github.com/UKDataServiceOpen/code-demos/blob/master/code/ukds-web-scraping-2020-05-13.ipynb\" target=_blank>*Collecting data I: web-scraping*</a>  lessons first.\n",
    "* **Audience**: Researchers and analysts from any disciplinary background. The materials are slightly tailored for social scientists through the use of social data.\n",
    "* **Learning outcomes**:\n",
    "    1. Understand what an Application Programming Interface (API) is.\n",
    "    2. Understand the key steps and requirements for collecting data from the web through an API.\n",
    "    3. Be able to use Python for requesting, processing and saving data accessed through an API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Guide to using this resource\n",
    "\n",
    "This learning resource was built using <a href=\"https://jupyter.org/\" target=_blank>Jupyter Notebook</a>, an open-source software application that allows you to mix code, results and narrative in a single document. As <a href=\"https://jupyter4edu.github.io/jupyter-edu-book/\" target=_blank>Barba et al. (2019)</a> espouse:\n",
    "> In a world where every subject matter can have a data-supported treatment, where computational devices are omnipresent and pervasive, the union of natural language and computation creates compelling communication and learning opportunities.\n",
    "\n",
    "If you are familiar with Jupyter notebooks then skip ahead to the main content (*What is an API?*). Otherwise, the following is a quick guide to navigating and interacting with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interaction\n",
    "\n",
    "**You only need to execute the code that is contained in sections which are marked by `In []`.**\n",
    "\n",
    "To execute a cell, click or double-click the cell and press the `Run` button on the top toolbar (you can also use the keyboard shortcut Shift + Enter).\n",
    "\n",
    "Try it for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Enter your name and press enter:\")\n",
    "name = input()\n",
    "print(\"\\r\")\n",
    "print(\"Hello {}, enjoy learning more about Python and web-scraping!\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Learn more\n",
    "\n",
    "Jupyter notebooks provide rich, flexible features for conducting and documenting your data analysis workflow. To learn more about additional notebook features, we recommend working through some of the <a href=\"https://github.com/darribas/gds19/blob/master/content/labs/lab_00.ipynb\" target=_blank>materials</a> provided by Dani Arribas-Bel at the University of Liverpool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is an API?\n",
    "\n",
    "An Application Programming Interface (API) is\n",
    "> a set of functions and procedures allowing the creation of applications that access the features or data of an operating system, application, or other service\" (Oxford English Dictionary). \n",
    "\n",
    "In essence: an API acts as an intermediary between software applications. Think of an API's role as similar to that of a translator faciliating a conversation between two individuals who do not speak the same language. Neither individual needs to know the other's language, just how to formulate their response in a way the translator can understand. Similarly, an API **simplifies** how applications communicate with each other.\n",
    "\n",
    "It performs this role by providing a set of protocols/standards for making *requests* and formulating *responses* between applications. For example, a smart phone application might need real-time traffic data from an online database. An API can validate the application's request for data, and handle the online database's response (i.e., the transfer of data to the application). In the absence of an API, the smart phone application would need to know a lot more technical information about the online database in order to communicate with it (e.g., what commands does the database understand?). But thanks to the API, the smart phone application only needs to know how to formulate a request that the API understands, which then communicates the request to the database and handles the response.\n",
    "\n",
    "Run the code below for a graphical representation of how an API works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"./images/ukds-apis-slides.mp4\", width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Why would you want to use an API?\n",
    "\n",
    "Many public, private and charitable institutions collect and share data of value to social scientists. Often they deposit their data to a data portal - e.g., <a href=\"https://data.gov.uk/\" target=_blank>UK Government Open Data</a> -, allowing you to download the files as and when needed. However, another approach they can adopt is to allow access to the underlying information that is stored in their database through an API. Using this method, individuals can send a customised *request* for information to the database; if the request is valid, the database *responds* by providing you with the information you asked for. Think of using an API as the difference between downloading a raw data file which then needs to be filtered to arrive at the information you need, and performing the filtering when you request the data, so only what you need is returned (the API method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is the general approach for accessing data through an API?\n",
    "\n",
    "We begin by identifying an online database containing information of interest. Then we need to **know** the following:\n",
    "1. The location of the API (i.e., web address) through which the database can be accessed. For example, the UK Police API can be accessed via <a href=\"https://data.police.uk/api\" target=_blank>https://data.police.uk/api</a>.\n",
    "2. The terms of use associated with the API. Many APIs restrict the number of requests you can make over a given time period, while others require registration in order to authenticate who is trying to access the data. For example, the UK Police API does not require you to provide authentication but restricts the number of requests for data you can make (15 per second) - the number of allowable requests is known as the *rate limit*.\n",
    "3. The location of the data of interest on the API. For example, data on street-level crime from the UK Police API is available at: <a href=\"https://data.police.uk/api/crimes-street\" target=_blank>https://data.police.uk/api/crimes-street</a>. The location of the data is known as its *endpoint*.\n",
    "\n",
    "We can usually find all of the information we need by reading the API's documentation e.g., <a href=\"https://data.police.uk/docs/\" target=_blank>https://data.police.uk/docs/</a>.\n",
    "\n",
    "Then we need to **do** the following:\n",
    "4. Register your use of the API (if required).\n",
    "5. Request data from the endpoint of interest, supplying authentication if required. This process is known as *making a call* to the API.\n",
    "6. Write this data to a file for future use.\n",
    "\n",
    "For any programming task, it is useful to write out the steps needed to solve the problem: we call this *pseudo-code*, as it is captures the main tasks and the order in which they need to be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A social science example\n",
    "\n",
    "Let's work through the steps in our general approach using a real API, one that provides data on policing activities and street-level crime in England and Wales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  Locating the API\n",
    "\n",
    "The UK Police API can be accessed via the following web address or link: <a href=\"https://data.police.uk/api\" target=_blank>https://data.police.uk/api</a>.\n",
    "\n",
    "Note that you cannot request this web address through your browser; this is because this link acts as the *base* web address from which you can access the different data sets. For example, we can access a list of all the police forces whose data is available via the API using the following web address: <a href=\"https://data.police.uk/api/forces\" target=_blank>https://data.police.uk/api/forces</a>.\n",
    "\n",
    "**TASK**: Try it yourself: click on the above link to see what happens when you request data on police forces.\n",
    "\n",
    "Before delving further into requesting data, let's understand the terms of use/restrictions associated with the UK Police API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### API terms of use\n",
    "\n",
    "The UK Police API is reasonably well documented (not always the case, unfortunately) and we can clearly identify what is required in order to interact with it. Firstly, the API does not require authentication: you do not need to register your use of the API, nor provide a password (known as an API key) whenever you request data.\n",
    "\n",
    "Secondly, the API allows you to make up to 15 calls (requests) per second on average, though you can make up to 30 in a single second. If you are using the API for research purposes, it is highly unlikely you'll exceed this limit (but who knows what data requirements you have).\n",
    "\n",
    "See <a href=\"https://data.police.uk/docs/api-call-limits/\" target=_blank>https://data.police.uk/docs/api-call-limits/</a> for full information on the API's call limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locating data\n",
    "\n",
    "The UK Police API allows access to over twenty endpoints (data sets), grouped under the following headings:\n",
    "* *Forces* e.g., senior officers\n",
    "* *Crime* e.g., crime categories\n",
    "* *Neighbourhoods* e.g., boundaries, events\n",
    "* *Stop and search* e.g., by area or force\n",
    "\n",
    "See <a href=\"https://data.police.uk/docs/\" target=_blank>https://data.police.uk/docs//</a> for a complete list of endpoints accessible through this API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering use of API\n",
    "\n",
    "We can skip this step as the UK Police API does not require us to register or provide any form of authentication (a good example of *open data*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting data\n",
    "\n",
    "We're ready for the interesting bit: requesting data through the API. To focus our activities, we'll attempt to do the following:\n",
    "1. Download a list of police forces in the UK.\n",
    "2. For each force, download its stop-and-search data.\n",
    "3. Save each data set to a file for future use.\n",
    "\n",
    "Before we download data, we need to ensure Python has the functionality it needs to interact with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import os # module for navigating your machine (e.g., file directories)\n",
    "import requests # module for requesting urls\n",
    "import json # module for working with JSON data structures\n",
    "from datetime import datetime # module for working with dates and time\n",
    "print(\"Succesfully imported necessary modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Modules are additional techniques or functions that are not present when you launch Python. Some do not even come with Python when you download it and must be installed on your machine separately - think of using `ssc install <package>` in Stata, or `install.packages(<package>)` in R. For now just understand that many useful modules need to be imported every time you start a new Python session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define web address and search terms\n",
    "\n",
    "baseurl = \"https://data.police.uk/api/\" # base web address\n",
    "forces = \"forces\" # endpoint where forces data is located\n",
    "\n",
    "webadd = baseurl + forces # construct web address to request\n",
    "print(webadd)\n",
    "\n",
    "# Make call to API\n",
    "\n",
    "response = requests.get(webadd) # request the web address\n",
    "response.status_code # check if API was requested successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack the above code. First, we define a variable (also known as an 'object' in Python) called `baseurl` that contains the base web address of the UK Police API. Then we define a variable containing the endpoint we want to access data from (`forces`). Finally we concatenate these separate elements to form a valid web address that can be requested from the API (`webadd`).\n",
    "\n",
    "The next step is to use the `get()` method of the `requests` module to request the web address, and in the same line of code, we store the results of the request in a variable called `response`. Finally, we check whether the request was successful by calling on the `status_code` attribute of the `response` variable.\n",
    "\n",
    "We get a status code of *200*, which means the request was successful. A status code in the *400s* or *500s* represent an unsuccessful attempt at requesting a web address (see <a href=\"https://www.textbook.ds100.org/ch/07/web_http.html\" target=_blank>Lau, Gonzalez and Nolan</a> for a succinct description of different types of response status codes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering exactly what it is we requested. To see the content of our request i.e., the data, we can call the `json()` method on the `response` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'avon-and-somerset', 'name': 'Avon and Somerset Constabulary'},\n",
       " {'id': 'bedfordshire', 'name': 'Bedfordshire Police'},\n",
       " {'id': 'cambridgeshire', 'name': 'Cambridgeshire Constabulary'},\n",
       " {'id': 'cheshire', 'name': 'Cheshire Constabulary'},\n",
       " {'id': 'city-of-london', 'name': 'City of London Police'},\n",
       " {'id': 'cleveland', 'name': 'Cleveland Police'},\n",
       " {'id': 'cumbria', 'name': 'Cumbria Constabulary'},\n",
       " {'id': 'derbyshire', 'name': 'Derbyshire Constabulary'},\n",
       " {'id': 'devon-and-cornwall', 'name': 'Devon & Cornwall Police'},\n",
       " {'id': 'dorset', 'name': 'Dorset Police'},\n",
       " {'id': 'durham', 'name': 'Durham Constabulary'},\n",
       " {'id': 'dyfed-powys', 'name': 'Dyfed-Powys Police'},\n",
       " {'id': 'essex', 'name': 'Essex Police'},\n",
       " {'id': 'gloucestershire', 'name': 'Gloucestershire Constabulary'},\n",
       " {'id': 'greater-manchester', 'name': 'Greater Manchester Police'},\n",
       " {'id': 'gwent', 'name': 'Gwent Police'},\n",
       " {'id': 'hampshire', 'name': 'Hampshire Constabulary'},\n",
       " {'id': 'hertfordshire', 'name': 'Hertfordshire Constabulary'},\n",
       " {'id': 'humberside', 'name': 'Humberside Police'},\n",
       " {'id': 'kent', 'name': 'Kent Police'},\n",
       " {'id': 'lancashire', 'name': 'Lancashire Constabulary'},\n",
       " {'id': 'leicestershire', 'name': 'Leicestershire Police'},\n",
       " {'id': 'lincolnshire', 'name': 'Lincolnshire Police'},\n",
       " {'id': 'merseyside', 'name': 'Merseyside Police'},\n",
       " {'id': 'metropolitan', 'name': 'Metropolitan Police Service'},\n",
       " {'id': 'norfolk', 'name': 'Norfolk Constabulary'},\n",
       " {'id': 'north-wales', 'name': 'North Wales Police'},\n",
       " {'id': 'north-yorkshire', 'name': 'North Yorkshire Police'},\n",
       " {'id': 'northamptonshire', 'name': 'Northamptonshire Police'},\n",
       " {'id': 'northumbria', 'name': 'Northumbria Police'},\n",
       " {'id': 'nottinghamshire', 'name': 'Nottinghamshire Police'},\n",
       " {'id': 'northern-ireland', 'name': 'Police Service of Northern Ireland'},\n",
       " {'id': 'south-wales', 'name': 'South Wales Police'},\n",
       " {'id': 'south-yorkshire', 'name': 'South Yorkshire Police'},\n",
       " {'id': 'staffordshire', 'name': 'Staffordshire Police'},\n",
       " {'id': 'suffolk', 'name': 'Suffolk Constabulary'},\n",
       " {'id': 'surrey', 'name': 'Surrey Police'},\n",
       " {'id': 'sussex', 'name': 'Sussex Police'},\n",
       " {'id': 'thames-valley', 'name': 'Thames Valley Police'},\n",
       " {'id': 'warwickshire', 'name': 'Warwickshire Police'},\n",
       " {'id': 'west-mercia', 'name': 'West Mercia Police'},\n",
       " {'id': 'west-midlands', 'name': 'West Midlands Police'},\n",
       " {'id': 'west-yorkshire', 'name': 'West Yorkshire Police'},\n",
       " {'id': 'wiltshire', 'name': 'Wiltshire Police'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forces_data = response.json()\n",
    "forces_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Voila, we have a list of police forces in the UK (excluding Scotland and the British Transport Police).\n",
    "\n",
    "We hope you agree that requesting data from an API is a relatively simple task. The real challenge lies with the way the data are *structured* in response to your request. While sometimes you may be able to request data in a tabular format (e.g., a CSV or Excel file), most of the time it arrives looking a bit different than you may be familiar with. For instance, we currently have a list of police forces, and for each one there are two fields: `id` and `name`. \n",
    "\n",
    "Therefore we need to figure out how to navigate these results and extract information of interest. Thankfully Python provides some intuitive methods for performing this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with lists\n",
    "\n",
    "A *list* is a data type in Python that contains ordered, mutable sequences of elements. Think of it as a variable that contains a certain type of value, just a like an *integer* variable can only contain whole numbers, or a *string* variable contains characters that should be treated as text. Knowing which data type you're working with is crucial as it determines the kind of operations you can perform on the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-639ac900777f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_number\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# this will work\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_string\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# this will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "my_number = 25\n",
    "my_string = \"Hello there!\"\n",
    "\n",
    "print(my_number + 50) # this will work\n",
    "print(my_string + 50) # this will not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to know is that we can confirm what data type a variable is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(forces_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also identify a list by the presence of opening and closing square brackets (`[]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can count how many elements a list contains like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forces_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can view each element in a list as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'avon-and-somerset', 'name': 'Avon and Somerset Constabulary'}\n",
      "\r\n",
      "{'id': 'bedfordshire', 'name': 'Bedfordshire Police'}\n",
      "\r\n",
      "{'id': 'cambridgeshire', 'name': 'Cambridgeshire Constabulary'}\n",
      "\r\n",
      "{'id': 'cheshire', 'name': 'Cheshire Constabulary'}\n",
      "\r\n",
      "{'id': 'city-of-london', 'name': 'City of London Police'}\n",
      "\r\n",
      "{'id': 'cleveland', 'name': 'Cleveland Police'}\n",
      "\r\n",
      "{'id': 'cumbria', 'name': 'Cumbria Constabulary'}\n",
      "\r\n",
      "{'id': 'derbyshire', 'name': 'Derbyshire Constabulary'}\n",
      "\r\n",
      "{'id': 'devon-and-cornwall', 'name': 'Devon & Cornwall Police'}\n",
      "\r\n",
      "{'id': 'dorset', 'name': 'Dorset Police'}\n",
      "\r\n",
      "{'id': 'durham', 'name': 'Durham Constabulary'}\n",
      "\r\n",
      "{'id': 'dyfed-powys', 'name': 'Dyfed-Powys Police'}\n",
      "\r\n",
      "{'id': 'essex', 'name': 'Essex Police'}\n",
      "\r\n",
      "{'id': 'gloucestershire', 'name': 'Gloucestershire Constabulary'}\n",
      "\r\n",
      "{'id': 'greater-manchester', 'name': 'Greater Manchester Police'}\n",
      "\r\n",
      "{'id': 'gwent', 'name': 'Gwent Police'}\n",
      "\r\n",
      "{'id': 'hampshire', 'name': 'Hampshire Constabulary'}\n",
      "\r\n",
      "{'id': 'hertfordshire', 'name': 'Hertfordshire Constabulary'}\n",
      "\r\n",
      "{'id': 'humberside', 'name': 'Humberside Police'}\n",
      "\r\n",
      "{'id': 'kent', 'name': 'Kent Police'}\n",
      "\r\n",
      "{'id': 'lancashire', 'name': 'Lancashire Constabulary'}\n",
      "\r\n",
      "{'id': 'leicestershire', 'name': 'Leicestershire Police'}\n",
      "\r\n",
      "{'id': 'lincolnshire', 'name': 'Lincolnshire Police'}\n",
      "\r\n",
      "{'id': 'merseyside', 'name': 'Merseyside Police'}\n",
      "\r\n",
      "{'id': 'metropolitan', 'name': 'Metropolitan Police Service'}\n",
      "\r\n",
      "{'id': 'norfolk', 'name': 'Norfolk Constabulary'}\n",
      "\r\n",
      "{'id': 'north-wales', 'name': 'North Wales Police'}\n",
      "\r\n",
      "{'id': 'north-yorkshire', 'name': 'North Yorkshire Police'}\n",
      "\r\n",
      "{'id': 'northamptonshire', 'name': 'Northamptonshire Police'}\n",
      "\r\n",
      "{'id': 'northumbria', 'name': 'Northumbria Police'}\n",
      "\r\n",
      "{'id': 'nottinghamshire', 'name': 'Nottinghamshire Police'}\n",
      "\r\n",
      "{'id': 'northern-ireland', 'name': 'Police Service of Northern Ireland'}\n",
      "\r\n",
      "{'id': 'south-wales', 'name': 'South Wales Police'}\n",
      "\r\n",
      "{'id': 'south-yorkshire', 'name': 'South Yorkshire Police'}\n",
      "\r\n",
      "{'id': 'staffordshire', 'name': 'Staffordshire Police'}\n",
      "\r\n",
      "{'id': 'suffolk', 'name': 'Suffolk Constabulary'}\n",
      "\r\n",
      "{'id': 'surrey', 'name': 'Surrey Police'}\n",
      "\r\n",
      "{'id': 'sussex', 'name': 'Sussex Police'}\n",
      "\r\n",
      "{'id': 'thames-valley', 'name': 'Thames Valley Police'}\n",
      "\r\n",
      "{'id': 'warwickshire', 'name': 'Warwickshire Police'}\n",
      "\r\n",
      "{'id': 'west-mercia', 'name': 'West Mercia Police'}\n",
      "\r\n",
      "{'id': 'west-midlands', 'name': 'West Midlands Police'}\n",
      "\r\n",
      "{'id': 'west-yorkshire', 'name': 'West Yorkshire Police'}\n",
      "\r\n",
      "{'id': 'wiltshire', 'name': 'Wiltshire Police'}\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "for el in forces_data:\n",
    "    print(el)\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can access a particular element in a list by referring to its location (i.e., positional value or index). For example, which police force is located in position 10 in the list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'dorset', 'name': 'Dorset Police'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forces_data[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python begins counting at zero, hence why the value \"9\" refers to position \"10\" in the list. Simple rule of thumb: element *n* is located in position *n-1* of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: extract a different police force from the list using another index value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'INSERT_INDEX_VALUE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ecdf3a30c4bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforces_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mINSERT_INDEX_VALUE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'INSERT_INDEX_VALUE' is not defined"
     ]
    }
   ],
   "source": [
    "forces_data[INSERT_INDEX_VALUE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now that we're familiar with lists we can extract the `id` for each force and store them in a separate list like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avon-and-somerset',\n",
       " 'bedfordshire',\n",
       " 'cambridgeshire',\n",
       " 'cheshire',\n",
       " 'city-of-london',\n",
       " 'cleveland',\n",
       " 'cumbria',\n",
       " 'derbyshire',\n",
       " 'devon-and-cornwall',\n",
       " 'dorset',\n",
       " 'durham',\n",
       " 'dyfed-powys',\n",
       " 'essex',\n",
       " 'gloucestershire',\n",
       " 'greater-manchester',\n",
       " 'gwent',\n",
       " 'hampshire',\n",
       " 'hertfordshire',\n",
       " 'humberside',\n",
       " 'kent',\n",
       " 'lancashire',\n",
       " 'leicestershire',\n",
       " 'lincolnshire',\n",
       " 'merseyside',\n",
       " 'metropolitan',\n",
       " 'norfolk',\n",
       " 'north-wales',\n",
       " 'north-yorkshire',\n",
       " 'northamptonshire',\n",
       " 'northumbria',\n",
       " 'nottinghamshire',\n",
       " 'northern-ireland',\n",
       " 'south-wales',\n",
       " 'south-yorkshire',\n",
       " 'staffordshire',\n",
       " 'suffolk',\n",
       " 'surrey',\n",
       " 'sussex',\n",
       " 'thames-valley',\n",
       " 'warwickshire',\n",
       " 'west-mercia',\n",
       " 'west-midlands',\n",
       " 'west-yorkshire',\n",
       " 'wiltshire']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "force_ids = [el[\"id\"] for el in forces_data]\n",
    "force_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct our list of force ids, we've made use of an intermediate technique in Python: *list comprehension*.\n",
    "\n",
    "We create a new list called `force_ids`, and we populate this variable with the values from the `id` field for each element (`el`) in the list (`forces_data`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop-and-search data\n",
    "\n",
    "Now that we have a list of force ids we can request their respective stop-and-search data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://data.police.uk/api/stops-force?force=avon-and-somerset',\n",
       " 'https://data.police.uk/api/stops-force?force=bedfordshire',\n",
       " 'https://data.police.uk/api/stops-force?force=cambridgeshire',\n",
       " 'https://data.police.uk/api/stops-force?force=cheshire',\n",
       " 'https://data.police.uk/api/stops-force?force=city-of-london',\n",
       " 'https://data.police.uk/api/stops-force?force=cleveland',\n",
       " 'https://data.police.uk/api/stops-force?force=cumbria',\n",
       " 'https://data.police.uk/api/stops-force?force=derbyshire',\n",
       " 'https://data.police.uk/api/stops-force?force=devon-and-cornwall',\n",
       " 'https://data.police.uk/api/stops-force?force=dorset',\n",
       " 'https://data.police.uk/api/stops-force?force=durham',\n",
       " 'https://data.police.uk/api/stops-force?force=dyfed-powys',\n",
       " 'https://data.police.uk/api/stops-force?force=essex',\n",
       " 'https://data.police.uk/api/stops-force?force=gloucestershire',\n",
       " 'https://data.police.uk/api/stops-force?force=greater-manchester',\n",
       " 'https://data.police.uk/api/stops-force?force=gwent',\n",
       " 'https://data.police.uk/api/stops-force?force=hampshire',\n",
       " 'https://data.police.uk/api/stops-force?force=hertfordshire',\n",
       " 'https://data.police.uk/api/stops-force?force=humberside',\n",
       " 'https://data.police.uk/api/stops-force?force=kent',\n",
       " 'https://data.police.uk/api/stops-force?force=lancashire',\n",
       " 'https://data.police.uk/api/stops-force?force=leicestershire',\n",
       " 'https://data.police.uk/api/stops-force?force=lincolnshire',\n",
       " 'https://data.police.uk/api/stops-force?force=merseyside',\n",
       " 'https://data.police.uk/api/stops-force?force=metropolitan',\n",
       " 'https://data.police.uk/api/stops-force?force=norfolk',\n",
       " 'https://data.police.uk/api/stops-force?force=north-wales',\n",
       " 'https://data.police.uk/api/stops-force?force=north-yorkshire',\n",
       " 'https://data.police.uk/api/stops-force?force=northamptonshire',\n",
       " 'https://data.police.uk/api/stops-force?force=northumbria',\n",
       " 'https://data.police.uk/api/stops-force?force=nottinghamshire',\n",
       " 'https://data.police.uk/api/stops-force?force=northern-ireland',\n",
       " 'https://data.police.uk/api/stops-force?force=south-wales',\n",
       " 'https://data.police.uk/api/stops-force?force=south-yorkshire',\n",
       " 'https://data.police.uk/api/stops-force?force=staffordshire',\n",
       " 'https://data.police.uk/api/stops-force?force=suffolk',\n",
       " 'https://data.police.uk/api/stops-force?force=surrey',\n",
       " 'https://data.police.uk/api/stops-force?force=sussex',\n",
       " 'https://data.police.uk/api/stops-force?force=thames-valley',\n",
       " 'https://data.police.uk/api/stops-force?force=warwickshire',\n",
       " 'https://data.police.uk/api/stops-force?force=west-mercia',\n",
       " 'https://data.police.uk/api/stops-force?force=west-midlands',\n",
       " 'https://data.police.uk/api/stops-force?force=west-yorkshire',\n",
       " 'https://data.police.uk/api/stops-force?force=wiltshire']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseurl = \"https://data.police.uk/api/\" # base web address\n",
    "sas = \"stops-force\" # stop-and-search endpoint\n",
    "\n",
    "webadd_list = [] # create a blank list for storing web addresses\n",
    "for el in force_ids: # for each id in the list\n",
    "    webadd = baseurl + sas + \"?force=\" + el # construct the web address for that force\n",
    "    webadd_list.append(webadd) # append the web address to the list\n",
    "    \n",
    "webadd_list # view the list of web addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Saving results from the scrape\n",
    "\n",
    "Let's conclude by saving the scraped data to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define a file to store the data\n",
    "\n",
    "outfile = \"./moby-dick-scraped-data.txt\" # location and name of file\n",
    "\n",
    "# Open the file and write (save) the data to it\n",
    "\n",
    "with open(outfile, \"w\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we know this worked? The simplest way is to check whether a) the file was created, and b) the results were written to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Check presence of file in current folder\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Open file and read (import) its contents\n",
    "\n",
    "with open(outfile, \"r\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "print(data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And Voila, we have successfully scraped a web page!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A social science example\n",
    "\n",
    "While the above example is good for learning the basics, scraping research-relevant data from a web page is a little more difficult:\n",
    "* Data may be spread throughout a web page (or across multiple pages).\n",
    "* There may be many tags with similar data that need to be filtered in order to get to the information you need.\n",
    "* And many other potential issues.\n",
    "\n",
    "Let's look at a social data example to get a better sense of what web-scraping for research involves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Collecting charity data\n",
    "\n",
    "For one of us (Diarmuid), web-scraping provides a means of collecting data that cannot be accessed any other way (other than manually copying-and-pasting from each charity's web page...). In particular, we are interested in collecting data about which policies a charity reportedly has in place. This information is interesting as it can be linked to observed organisational outcomes (e.g., is there a correlation between not having a risk policy and going out of business?).\n",
    "\n",
    "Once again we'll work through the key steps in our general approach, this time a bit quicker and with less narrative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import requests # module for requesting urls\n",
    "import os # module for performing operating system tasks\n",
    "import pandas as pd # module for working with datasets\n",
    "from IPython.display import IFrame # module for embedding web pages, documents etc\n",
    "from bs4 import BeautifulSoup as soup # module for parsing web pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  Identifying the web address\n",
    "\n",
    "We're going to use the Charity Commission for England and Wales' website to capture policy data: <a href=\"https://beta.charitycommission.gov.uk/\" target=_blank>https://beta.charitycommission.gov.uk/</a>\n",
    "\n",
    "We're going to focus on just one charity for now - Oxfam; therefore the web address looks like this: <a href=\"https://beta.charitycommission.gov.uk/charity-details/?regId=202918&subId=0\" target=_blank>https://beta.charitycommission.gov.uk/charity-details/?regId=202918&subId=0</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "IFrame(\"https://beta.charitycommission.gov.uk/charity-details/?regId=202918&subId=0\", width=\"800\", height=\"650\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Locating information\n",
    "\n",
    "Policy data is located in the *Documents* tab under a heading called *Policies*, which in terms of the source code is here:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"pcg-charity-details__block col-lg-6\">\n",
    "    <h3>Policies</h3>\n",
    "        <span>Risk management</span>\n",
    "        <br />\n",
    "        <span>Investment</span>\n",
    "        <br />\n",
    "        <span>Safeguarding vulnerable beneficiaries</span>\n",
    "        <br />\n",
    "        <span>Conflicts of interest</span>\n",
    "        <br />\n",
    "        <span>Volunteer management</span>\n",
    "        <br />\n",
    "        <span>Complaints handling</span>\n",
    "        <br />\n",
    "        <span>Paying staff</span>\n",
    "        <br />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Requesting the web page\n",
    "\n",
    "Now that we possess the necessary information, let's begin the process of scraping the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://beta.charitycommission.gov.uk/charity-details/?regId=202918&subId=0\"\n",
    "\n",
    "response = requests.get(url, allow_redirects=True)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parsing the web page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup_response = soup(response.text, \"html.parser\")\n",
    "# soup_response.body # view HTML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup_response.find_all(\"a\")\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Extracting information\n",
    "\n",
    "The policies are contained within a set of `<div></div>` tags where the *class* attribute equals \"pcg-charity-details__block col-lg-6\". There are multiple sets of tags with this id, therefore we need to use the `find_all()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sections = soup_response.find_all(\"div\", class_=\"pcg-charity-details__block col-lg-6\")\n",
    "len(sections) # view how many sets of tags are returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Multiple sets of tags are returned, therefore how can we identify the correct set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "searchterm = \"Policies\" # search term identifying section containing list of policies\n",
    "\n",
    "for section in sections: # for each section contained in the sections list:\n",
    "    if searchterm in str(section): # if the search term exists in the section\n",
    "        policy_location = sections.index(section) # store the list location of the correct section\n",
    "        print(policy_location) # view the location of the policies in the list (i.e, is it the first element in the list?)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "policy_section = sections[policy_location] # create a new variable containing the correct section\n",
    "policy_section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's unpick the logic of the code above:\n",
    "1. We know the list of policies is contained in a section (`<div>`) where *class_=\"pcg-charity-details__block col-lg-6\"*.\n",
    "2. We find all sections where the _class_ attribute equals \"pcg-charity-details__block col-lg-6\", and navigate to the correct one by evaluating whether it contains a relevant piece of text (\"Policies\"). This process revealed that the list of policies was contained in the sixth section (remember: lists begin at position 0, so 5 identifies the sixth element of a list). If we knew that the list of beneficiaries was always contained in the fifth section we wouldn't need the use of a search term, but this way is more robust to deviations in the structure and content of each charity's web page.\n",
    "\n",
    "Now that we have the correct set of `<div></div>` tags, we need to extract the policy data from with the `<span></span>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "policy_list = [] # define a blank list for storing the policy data\n",
    "charity_name = \"Oxfam\" # define a variable for storing the charity's name\n",
    "\n",
    "for tag in policy_section.find_all(\"span\"): # for each set of span tags in the policy section\n",
    "    policy = tag.text # extract the text from the tag\n",
    "    observation = [charity_name, policy] # combine charity name and a policy\n",
    "    policy_list.append(observation) # append the charity name and policy to the blank list\n",
    "    \n",
    "policy_list # view list of policies for the charity (long format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Again, let's unpack the code above:\n",
    "1. We define a variable called `policy_list` which will store the extracted text; at this point the list is empty. We also define a variable for storing the charity's name (`charity_name`).\n",
    "2. Then, for each set of `<span></span>` tags in the `policy_section` variable, we extract the text from within the tags. We also define a variable called `observation` with stores a list of values: a charity's name and a given policy; finally we append the information to the empty list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Saving results from the scrape\n",
    "\n",
    "Let's conclude by saving the scraped data to a file for future use. We'll make use of the excellent `pandas` module (shortened to `pd`) for converting the extracted text to a dataset prior to writing to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "policy_data = pd.DataFrame(list(policy_list), columns=[\"charity_name\", \"policy\"])\n",
    "policy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Finally, we can save the data set to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "outfile = \"./oxfam_policies.csv\"\n",
    "\n",
    "policy_data.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(outfile, encoding=\"ISO-8859-1\", index_col=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What have we learned?\n",
    "\n",
    "Let's recap what key skills and techniques we've learned:\n",
    "* **How to import modules**. You will usually need to import modules into Python to support your work. Python does come with some methods and functions that are ready to use straight away, but for computational social science tasks you'll almost certainly need to import some additional modules.\n",
    "* **How to request and parse web pages**. You can use Python to request a web page, and the `BeautifulSoup` module to parse its contents.\n",
    "* **How to read and write data**. You can save the results of your scrape to a file for future use.\n",
    "* **How to do all of the above in an efficient, clear and effective manner**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Web-scraping is a simple yet powerful computational method for collecting data of value for social science research. It provides a relatively gentle introduction to using programming languages, also. However, \"with great power comes great responsibility\" (sorry). Web-scraping takes you into the realm of data protection, website Terms of Service (ToS), and many murky ethical issues. Wielded sensibly and sensitively, web-scraping is a valuable and exciting social science research method. \n",
    "\n",
    "Good luck on your data-driven travels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Bibliography\n",
    "\n",
    "Barba, Lorena A. et al. (2019). *Teaching and Learning with Jupyter*. <a href=\"https://jupyter4edu.github.io/jupyter-edu-book/\" target=_blank>https://jupyter4edu.github.io/jupyter-edu-book/</a>.\n",
    "\n",
    "Lau, S., Gonzalez, J., & Nolan, D. (n.d.). *Principles and Techniques of Data Science*. https://www.textbook.ds100.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Further reading and resources\n",
    "\n",
    "We hope this brief lession has whetted your appetite for learning more about web-scraping and Python programming in general. There are some fantastic learning materials available to you, many of them free. We highly recommend the materials referenced in the Bibliography.\n",
    "\n",
    "In addition, you may find the following resources useful:\n",
    "* <a href=\"https://github.com/UKDataServiceOpen/web-scraping\" target=_blank>**Web-scraping for Social Science Research**</a> - a free UK Data Service training series on web-scraping, with three webinars and lots of detailed coding examples.\n",
    "* <a href=\"https://automatetheboringstuff.com/\" target=_blank>**Automate the Boring Stuff with Python**</a> - a free ebook covering lots of interesting, practical uses of Python. Chapter 12 covers web-scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "--END OF FILE--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "256px",
    "width": "221px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
